

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>espnet.nets package &mdash; ESPnet 0.4.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'0.4.1',
              LANGUAGE:'None',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="espnet.transform package" href="espnet-transform.html" />
    <link rel="prev" title="espnet.lm package" href="espnet-lm.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> ESPnet
          

          
          </a>

          
            
            
              <div class="version">
                0.4.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Tutorial:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Outline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html#execution-of-example-scripts">Execution of example scripts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html#demonstration-using-pretrained-models">Demonstration using pretrained models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html#installation-using-docker">Installation using Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html#references">References</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="espnet-asr.html">espnet.asr package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet-lm.html">espnet.lm package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">espnet.nets package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-asr-interface">espnet.nets.asr_interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend">espnet.nets.chainer_backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-attentions">espnet.nets.chainer_backend.attentions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-attentions-transformer">espnet.nets.chainer_backend.attentions_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-ctc">espnet.nets.chainer_backend.ctc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-decoders">espnet.nets.chainer_backend.decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-decoders-transformer">espnet.nets.chainer_backend.decoders_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-deterministic-embed-id">espnet.nets.chainer_backend.deterministic_embed_id</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-e2e-asr">espnet.nets.chainer_backend.e2e_asr</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-e2e-asr-transformer">espnet.nets.chainer_backend.e2e_asr_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-encoders">espnet.nets.chainer_backend.encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-encoders-transformer">espnet.nets.chainer_backend.encoders_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-nets-utils">espnet.nets.chainer_backend.nets_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-chainer-backend-nets-utils-transformer">espnet.nets.chainer_backend.nets_utils_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-ctc-prefix-score">espnet.nets.ctc_prefix_score</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-e2e-asr-common">espnet.nets.e2e_asr_common</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend">espnet.nets.pytorch_backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-ctc">espnet.nets.pytorch_backend.ctc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-asr">espnet.nets.pytorch_backend.e2e_asr</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-asr-mix">espnet.nets.pytorch_backend.e2e_asr_mix</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-asr-transformer">espnet.nets.pytorch_backend.e2e_asr_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-tts-tacotron2">espnet.nets.pytorch_backend.e2e_tts_tacotron2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-e2e-tts-transformer">espnet.nets.pytorch_backend.e2e_tts_transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-frontends">espnet.nets.pytorch_backend.frontends</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-nets-utils">espnet.nets.pytorch_backend.nets_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-rnn">espnet.nets.pytorch_backend.rnn</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-streaming">espnet.nets.pytorch_backend.streaming</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-tacotron2">espnet.nets.pytorch_backend.tacotron2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-pytorch-backend-transformer">espnet.nets.pytorch_backend.transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espnet-nets-tts-interface">espnet.nets.tts_interface</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="espnet-transform.html">espnet.transform package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet-tts.html">espnet.tts package</a></li>
<li class="toctree-l1"><a class="reference internal" href="espnet-utils.html">espnet.utils package</a></li>
</ul>
<p class="caption"><span class="caption-text">Tool Reference:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apis/espnet_bin.html">core tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_py.html">python utility tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apis/utils_sh.html">bash utility tools</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ESPnet</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>espnet.nets package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/_gen/espnet-nets.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="espnet-nets-package">
<h1>espnet.nets package<a class="headerlink" href="#espnet-nets-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="espnet-nets-asr-interface">
<span id="id1"></span><h2>espnet.nets.asr_interface<a class="headerlink" href="#espnet-nets-asr-interface" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.asr_interface"></span><dl class="class">
<dt id="espnet.nets.asr_interface.ASRInterface">
<em class="property">class </em><code class="descclassname">espnet.nets.asr_interface.</code><code class="descname">ASRInterface</code><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>ASR Interface for ESPnet model implementation</p>
<dl class="staticmethod">
<dt id="espnet.nets.asr_interface.ASRInterface.add_arguments">
<em class="property">static </em><code class="descname">add_arguments</code><span class="sig-paren">(</span><em>parser</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet.nets.asr_interface.ASRInterface.attention_plot_class">
<code class="descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.calculate_all_attentions">
<code class="descname">calculate_all_attentions</code><span class="sig-paren">(</span><em>xs</em>, <em>ilens</em>, <em>ys</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>attention calculation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs_pad</strong> (<em>list</em>) – list of padded input sequences [(T1, idim), (T2, idim), …]</li>
<li><strong>ilens</strong> (<em>ndarray</em>) – batch of lengths of input sequences (B)</li>
<li><strong>ys</strong> (<em>list</em>) – list of character id sequence tensor [(L1), (L2), (L3), …]</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">attention weights (B, Lmax, Tmax)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float ndarray</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>xs</em>, <em>ilens</em>, <em>ys</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>compute loss for training</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs</strong> – For pytorch, batch of padded source sequences torch.Tensor (B, Tmax, idim)
For chainer, list of source sequences chainer.Variable</li>
<li><strong>ilens</strong> – batch of lengths of source sequences (B)
For pytorch, torch.Tensor
For chainer, list of int</li>
<li><strong>ys</strong> – For pytorch, batch of padded source sequences torch.Tensor (B, Lmax)
For chainer, list of source sequences chainer.Variable</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor for pytorch, chainer.Variable for chainer</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.asr_interface.ASRInterface.recognize">
<code class="descname">recognize</code><span class="sig-paren">(</span><em>x</em>, <em>recog_args</em>, <em>char_list=None</em>, <em>rnnlm=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.asr_interface.ASRInterface.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>recognize x for evaluation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>ndarray</em>) – input acouctic feature (B, T, D) or (T, D)</li>
<li><strong>recog_args</strong> (<em>namespace</em>) – argment namespace contraining options</li>
<li><strong>char_list</strong> (<em>list</em>) – list of characters</li>
<li><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-best decoding results</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend">
<span id="id2"></span><h2>espnet.nets.chainer_backend<a class="headerlink" href="#espnet-nets-chainer-backend" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend"></span></div>
<div class="section" id="espnet-nets-chainer-backend-attentions">
<span id="id3"></span><h2>espnet.nets.chainer_backend.attentions<a class="headerlink" href="#espnet-nets-chainer-backend-attentions" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.attentions"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.attentions.AttDot">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.attentions.</code><code class="descname">AttDot</code><span class="sig-paren">(</span><em>eprojs</em>, <em>dunits</em>, <em>att_dim</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.attentions.AttDot" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.attentions.AttDot.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.attentions.AttDot.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.attentions.AttLoc">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.attentions.</code><code class="descname">AttLoc</code><span class="sig-paren">(</span><em>eprojs</em>, <em>dunits</em>, <em>att_dim</em>, <em>aconv_chans</em>, <em>aconv_filts</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.attentions.AttLoc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.attentions.AttLoc.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.attentions.AttLoc.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.attentions.NoAtt">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.attentions.</code><code class="descname">NoAtt</code><a class="headerlink" href="#espnet.nets.chainer_backend.attentions.NoAtt" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.attentions.NoAtt.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.attentions.NoAtt.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>reset states</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.attentions.att_for">
<code class="descclassname">espnet.nets.chainer_backend.attentions.</code><code class="descname">att_for</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.attentions.att_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an attention given the program arguments</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>args</strong> (<em>Namespace</em>) – the arguments</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The corresponding attention module</td>
</tr>
</tbody>
</table>
<p>:rtype chainer.Chain</p>
</dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend-attentions-transformer">
<span id="id4"></span><h2>espnet.nets.chainer_backend.attentions_transformer<a class="headerlink" href="#espnet-nets-chainer-backend-attentions-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.attentions_transformer"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.attentions_transformer.MultiHeadAttention">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.attentions_transformer.</code><code class="descname">MultiHeadAttention</code><span class="sig-paren">(</span><em>n_units</em>, <em>h=8</em>, <em>dropout=0.1</em>, <em>initialW=None</em>, <em>initial_bias=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.attentions_transformer.MultiHeadAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Multi Head Attention Layer</p>
</dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend-ctc">
<span id="id5"></span><h2>espnet.nets.chainer_backend.ctc<a class="headerlink" href="#espnet-nets-chainer-backend-ctc" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.ctc"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.ctc.CTC">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.ctc.</code><code class="descname">CTC</code><span class="sig-paren">(</span><em>odim</em>, <em>eprojs</em>, <em>dropout_rate</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.ctc.CTC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.ctc.CTC.log_softmax">
<code class="descname">log_softmax</code><span class="sig-paren">(</span><em>hs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.ctc.CTC.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>log_softmax of frame activations</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hs</strong> – </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.ctc.WarpCTC">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.ctc.</code><code class="descname">WarpCTC</code><span class="sig-paren">(</span><em>odim</em>, <em>eprojs</em>, <em>dropout_rate</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.ctc.WarpCTC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.ctc.WarpCTC.log_softmax">
<code class="descname">log_softmax</code><span class="sig-paren">(</span><em>hs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.ctc.WarpCTC.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>log_softmax of frame activations</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hs</strong> – </td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.ctc.ctc_for">
<code class="descclassname">espnet.nets.chainer_backend.ctc.</code><code class="descname">ctc_for</code><span class="sig-paren">(</span><em>args</em>, <em>odim</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.ctc.ctc_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the CTC corresponding to the args</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>args</strong> (<em>Namespace</em>) – The program arguments</li>
<li><strong>odim</strong> (<em>int</em>) – The output dimension</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The CTC module</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend-decoders">
<span id="id6"></span><h2>espnet.nets.chainer_backend.decoders<a class="headerlink" href="#espnet-nets-chainer-backend-decoders" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.decoders"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.decoders.Decoder">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.decoders.</code><code class="descname">Decoder</code><span class="sig-paren">(</span><em>eprojs</em>, <em>odim</em>, <em>dtype</em>, <em>dlayers</em>, <em>dunits</em>, <em>sos</em>, <em>eos</em>, <em>att</em>, <em>verbose=0</em>, <em>char_list=None</em>, <em>labeldist=None</em>, <em>lsm_weight=0.0</em>, <em>sampling_probability=0.0</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.decoders.Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.decoders.Decoder.calculate_all_attentions">
<code class="descname">calculate_all_attentions</code><span class="sig-paren">(</span><em>hs</em>, <em>ys</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.decoders.Decoder.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate all of attentions</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">list of attentions</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.decoders.Decoder.recognize_beam">
<code class="descname">recognize_beam</code><span class="sig-paren">(</span><em>h</em>, <em>lpz</em>, <em>recog_args</em>, <em>char_list</em>, <em>rnnlm=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.decoders.Decoder.recognize_beam" title="Permalink to this definition">¶</a></dt>
<dd><p>beam search implementation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>h</strong> – </li>
<li><strong>lpz</strong> – </li>
<li><strong>recog_args</strong> – </li>
<li><strong>char_list</strong> – </li>
<li><strong>rnnlm</strong> – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.decoders.Decoder.rnn_forward">
<code class="descname">rnn_forward</code><span class="sig-paren">(</span><em>ey</em>, <em>z_list</em>, <em>c_list</em>, <em>z_prev</em>, <em>c_prev</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.decoders.Decoder.rnn_forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.decoders.decoder_for">
<code class="descclassname">espnet.nets.chainer_backend.decoders.</code><code class="descname">decoder_for</code><span class="sig-paren">(</span><em>args</em>, <em>odim</em>, <em>sos</em>, <em>eos</em>, <em>att</em>, <em>labeldist</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.decoders.decoder_for" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend-decoders-transformer">
<span id="id7"></span><h2>espnet.nets.chainer_backend.decoders_transformer<a class="headerlink" href="#espnet-nets-chainer-backend-decoders-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.decoders_transformer"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.decoders_transformer.Decoder">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.decoders_transformer.</code><code class="descname">Decoder</code><span class="sig-paren">(</span><em>odim</em>, <em>n_layers</em>, <em>n_units</em>, <em>d_units=0</em>, <em>h=8</em>, <em>dropout=0.1</em>, <em>initialW=None</em>, <em>initial_bias=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.decoders_transformer.Decoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.decoders_transformer.DecoderLayer">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.decoders_transformer.</code><code class="descname">DecoderLayer</code><span class="sig-paren">(</span><em>n_units</em>, <em>d_units=0</em>, <em>h=8</em>, <em>dropout=0.1</em>, <em>initialW=None</em>, <em>initial_bias=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.decoders_transformer.DecoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
</dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend-deterministic-embed-id">
<span id="id8"></span><h2>espnet.nets.chainer_backend.deterministic_embed_id<a class="headerlink" href="#espnet-nets-chainer-backend-deterministic-embed-id" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.deterministic_embed_id"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedID">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.deterministic_embed_id.</code><code class="descname">EmbedID</code><span class="sig-paren">(</span><em>in_size</em>, <em>out_size</em>, <em>initialW=None</em>, <em>ignore_label=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedID" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Link</span></code></p>
<p>Efficient linear layer for one-hot input.</p>
<p>This is a link that wraps the <code class="xref py py-func docutils literal notranslate"><span class="pre">embed_id()</span></code> function.
This link holds the ID (word) embedding matrix <code class="docutils literal notranslate"><span class="pre">W</span></code> as a parameter.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>in_size</strong> (<em>int</em>) – Number of different identifiers (a.k.a. vocabulary size)</li>
<li><strong>out_size</strong> (<em>int</em>) – Initializer to initialize the weight. When it is np.ndarray, its ndim should be 2</li>
<li><strong>ignore_label</strong> (<em>int</em>) – If <cite>ignore_label</cite> is an int value, i-th column of return value is filled with 0</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><code class="xref py py-func docutils literal notranslate"><span class="pre">embed_id()</span></code></p>
</div>
<dl class="docutils">
<dt>Attributes:</dt>
<dd>W (~chainer.Variable): Embedding parameter matrix.</dd>
</dl>
<div class="admonition-example admonition">
<p class="first admonition-title">Example</p>
<div class="last highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">W</span>
<span class="go">array([[ 0.,  0.,  0.],</span>
<span class="go">       [ 1.,  1.,  1.],</span>
<span class="go">       [ 2.,  2.,  2.]], dtype=float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">EmbedID</span><span class="p">(</span><span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">initialW</span><span class="o">=</span><span class="n">W</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;i&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">array([2, 1], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">l</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">data</span>
<span class="go">array([[ 2.,  2.,  2.],</span>
<span class="go">       [ 1.,  1.,  1.]], dtype=float32)</span>
</pre></div>
</div>
</div>
<dl class="attribute">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedID.ignore_label">
<code class="descname">ignore_label</code><em class="property"> = None</em><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedID.ignore_label" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.deterministic_embed_id.</code><code class="descname">EmbedIDFunction</code><span class="sig-paren">(</span><em>ignore_label=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.function_node.FunctionNode</span></code></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.backward">
<code class="descname">backward</code><span class="sig-paren">(</span><em>indexes</em>, <em>grad_outputs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes gradients w.r.t. specified inputs given output gradients.</p>
<p>This method is used to compute one step of the backpropagation
corresponding to the forward computation of this function node.
Given the gradients w.r.t. output variables, this method computes the
gradients w.r.t. specified input variables. Note that this method does
not need to compute any input gradients not specified by
<code class="docutils literal notranslate"><span class="pre">target_input_indices</span></code>.</p>
<p>Unlike <code class="xref py py-meth docutils literal notranslate"><span class="pre">Function.backward()</span></code>,
gradients are given as  <code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code> objects and this
method itself has to return input gradients as
<code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code> objects. It enables the function node to
return the input gradients with the full computational history, in
which case it supports <em>differentiable backpropagation</em> or
<em>higher-order differentiation</em>.</p>
<p>The default implementation returns <code class="docutils literal notranslate"><span class="pre">None</span></code> s, which means the
function is not differentiable.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>target_input_indexes (tuple of int): Sorted indices of the input</dt>
<dd>variables w.r.t. which the gradients are required. It is
guaranteed that this tuple contains at least one element.</dd>
<dt>grad_outputs (tuple of <code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code>s): Gradients</dt>
<dd>w.r.t. the output variables.
If the gradient w.r.t. an output variable is not
given, the corresponding element is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd>Tuple of variables that represent the gradients w.r.t. specified
input variables. The length of the tuple can be same as either
<code class="docutils literal notranslate"><span class="pre">len(target_input_indexes)</span></code> or the number of inputs. In the
latter case, the elements not specified by <code class="docutils literal notranslate"><span class="pre">target_input_indexes</span></code>
will be discarded.</dd>
</dl>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><code class="xref py py-meth docutils literal notranslate"><span class="pre">backward_accumulate()</span></code> provides an alternative interface that
allows you to implement the backward computation fused with the
gradient accumulation.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.check_type_forward">
<code class="descname">check_type_forward</code><span class="sig-paren">(</span><em>in_types</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.check_type_forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks types of input data before forward propagation.</p>
<p>This method is called before <a class="reference internal" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward" title="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> and validates the types of
input variables using
<span class="xref std std-ref">the type checking utilities</span>.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>in_types (~chainer.utils.type_check.TypeInfoTuple): The type</dt>
<dd>information of input variables for <a class="reference internal" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward" title="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a>.</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDFunction.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the output arrays from the input arrays.</p>
<p>It delegates the procedure to <code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_cpu()</span></code> or
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_gpu()</span></code> by default. Which of them this method selects is
determined by the type of input arrays. Implementations of
<code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionNode</span></code> must implement either CPU/GPU methods or this
method.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>inputs: Tuple of input array(s).</dd>
<dt>Returns:</dt>
<dd>Tuple of output array(s).</dd>
</dl>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Implementations of <code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionNode</span></code> must take care that the
return value must be a tuple even if it returns only one array.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.deterministic_embed_id.</code><code class="descname">EmbedIDGrad</code><span class="sig-paren">(</span><em>w_shape</em>, <em>ignore_label=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.function_node.FunctionNode</span></code></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad.backward">
<code class="descname">backward</code><span class="sig-paren">(</span><em>indexes</em>, <em>grads</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes gradients w.r.t. specified inputs given output gradients.</p>
<p>This method is used to compute one step of the backpropagation
corresponding to the forward computation of this function node.
Given the gradients w.r.t. output variables, this method computes the
gradients w.r.t. specified input variables. Note that this method does
not need to compute any input gradients not specified by
<code class="docutils literal notranslate"><span class="pre">target_input_indices</span></code>.</p>
<p>Unlike <code class="xref py py-meth docutils literal notranslate"><span class="pre">Function.backward()</span></code>,
gradients are given as  <code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code> objects and this
method itself has to return input gradients as
<code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code> objects. It enables the function node to
return the input gradients with the full computational history, in
which case it supports <em>differentiable backpropagation</em> or
<em>higher-order differentiation</em>.</p>
<p>The default implementation returns <code class="docutils literal notranslate"><span class="pre">None</span></code> s, which means the
function is not differentiable.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><dl class="first last docutils">
<dt>target_input_indexes (tuple of int): Sorted indices of the input</dt>
<dd>variables w.r.t. which the gradients are required. It is
guaranteed that this tuple contains at least one element.</dd>
<dt>grad_outputs (tuple of <code class="xref py py-class docutils literal notranslate"><span class="pre">Variable</span></code>s): Gradients</dt>
<dd>w.r.t. the output variables.
If the gradient w.r.t. an output variable is not
given, the corresponding element is <code class="docutils literal notranslate"><span class="pre">None</span></code>.</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd>Tuple of variables that represent the gradients w.r.t. specified
input variables. The length of the tuple can be same as either
<code class="docutils literal notranslate"><span class="pre">len(target_input_indexes)</span></code> or the number of inputs. In the
latter case, the elements not specified by <code class="docutils literal notranslate"><span class="pre">target_input_indexes</span></code>
will be discarded.</dd>
</dl>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><code class="xref py py-meth docutils literal notranslate"><span class="pre">backward_accumulate()</span></code> provides an alternative interface that
allows you to implement the backward computation fused with the
gradient accumulation.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>inputs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.EmbedIDGrad.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the output arrays from the input arrays.</p>
<p>It delegates the procedure to <code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_cpu()</span></code> or
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward_gpu()</span></code> by default. Which of them this method selects is
determined by the type of input arrays. Implementations of
<code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionNode</span></code> must implement either CPU/GPU methods or this
method.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>inputs: Tuple of input array(s).</dd>
<dt>Returns:</dt>
<dd>Tuple of output array(s).</dd>
</dl>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Implementations of <code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionNode</span></code> must take care that the
return value must be a tuple even if it returns only one array.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.deterministic_embed_id.embed_id">
<code class="descclassname">espnet.nets.chainer_backend.deterministic_embed_id.</code><code class="descname">embed_id</code><span class="sig-paren">(</span><em>x</em>, <em>W</em>, <em>ignore_label=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.deterministic_embed_id.embed_id" title="Permalink to this definition">¶</a></dt>
<dd><p>Efficient linear function for one-hot input.</p>
<p>This function implements so called <em>word embeddings</em>. It takes two
arguments: a set of IDs (words) <code class="docutils literal notranslate"><span class="pre">x</span></code> in <span class="math notranslate nohighlight">\(B\)</span> dimensional integer
vector, and a set of all ID (word) embeddings <code class="docutils literal notranslate"><span class="pre">W</span></code> in <span class="math notranslate nohighlight">\(V \times d\)</span>
float32 matrix. It outputs <span class="math notranslate nohighlight">\(B \times d\)</span> matrix whose <code class="docutils literal notranslate"><span class="pre">i</span></code>-th
column is the <code class="docutils literal notranslate"><span class="pre">x[i]</span></code>-th column of <code class="docutils literal notranslate"><span class="pre">W</span></code>.</p>
<p>This function is only differentiable on the input <code class="docutils literal notranslate"><span class="pre">W</span></code>.</p>
<p>:param chainer.Variable | np.ndarray x : Batch vectors of IDs. Each element must be signed integer
:param chainer.Variable | np.ndarray W : Distributed representation of each ID (a.k.a. word embeddings)
:param int ignore_label : If ignore_label is an int value, i-th column of return value is filled with 0
:return Output variable
:rtype chainer.Variable</p>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><code class="xref py py-class docutils literal notranslate"><span class="pre">EmbedID</span></code></p>
</div>
<div class="admonition-example admonition">
<p class="first admonition-title">Example</p>
<div class="last highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;i&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">array([2, 1], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;f&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">W</span>
<span class="go">array([[ 0.,  0.,  0.],</span>
<span class="go">       [ 1.,  1.,  1.],</span>
<span class="go">       [ 2.,  2.,  2.]], dtype=float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F</span><span class="o">.</span><span class="n">embed_id</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
<span class="go">array([[ 2.,  2.,  2.],</span>
<span class="go">       [ 1.,  1.,  1.]], dtype=float32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">F</span><span class="o">.</span><span class="n">embed_id</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">ignore_label</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
<span class="go">array([[ 2.,  2.,  2.],</span>
<span class="go">       [ 0.,  0.,  0.]], dtype=float32)</span>
</pre></div>
</div>
</div>
</dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend-e2e-asr">
<span id="id9"></span><h2>espnet.nets.chainer_backend.e2e_asr<a class="headerlink" href="#espnet-nets-chainer-backend-e2e-asr" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.e2e_asr"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.e2e_asr.</code><code class="descname">E2E</code><span class="sig-paren">(</span><em>idim</em>, <em>odim</em>, <em>args</em>, <em>flag_return=True</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E.calculate_all_attentions">
<code class="descname">calculate_all_attentions</code><span class="sig-paren">(</span><em>xs</em>, <em>ilens</em>, <em>ys</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs</strong> (<em>list</em>) – </li>
<li><strong>xs</strong> – list of padded input sequences [(T1, idim), (T2, idim), …]</li>
<li><strong>ilens</strong> (<em>np.ndarray</em>) – batch of lengths of input sequences (B)</li>
<li><strong>ys</strong> (<em>list</em>) – list of character id sequence tensor [(L1), (L2), (L3), …]</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">attention weights (B, Lmax, Tmax)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float np.ndarray</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>xs</em>, <em>ilens</em>, <em>ys</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs</strong> – </li>
<li><strong>ilens</strong> – </li>
<li><strong>ys</strong> – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr.E2E.recognize">
<code class="descname">recognize</code><span class="sig-paren">(</span><em>x</em>, <em>recog_args</em>, <em>char_list</em>, <em>rnnlm=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E greedy/beam search</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> – </li>
<li><strong>recog_args</strong> – </li>
<li><strong>char_list</strong> – </li>
<li><strong>rnnlm</strong> – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend-e2e-asr-transformer">
<span id="id10"></span><h2>espnet.nets.chainer_backend.e2e_asr_transformer<a class="headerlink" href="#espnet-nets-chainer-backend-e2e-asr-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.e2e_asr_transformer"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.e2e_asr_transformer.</code><code class="descname">E2E</code><span class="sig-paren">(</span><em>idim</em>, <em>odim</em>, <em>args</em>, <em>ignore_id=-1</em>, <em>flag_return=True</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<dl class="staticmethod">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.add_arguments">
<em class="property">static </em><code class="descname">add_arguments</code><span class="sig-paren">(</span><em>parser</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.attention_plot_class">
<code class="descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.calculate_all_attentions">
<code class="descname">calculate_all_attentions</code><span class="sig-paren">(</span><em>xs</em>, <em>ilens</em>, <em>ys</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs_pad</strong> (<em>list</em>) – list of padded input sequences [(T1, idim), (T2, idim), …]</li>
<li><strong>ilens</strong> (<em>ndarray</em>) – batch of lengths of input sequences (B)</li>
<li><strong>ys</strong> (<em>list</em>) – list of character id sequence tensor [(L1), (L2), (L3), …]</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">attention weights (B, Lmax, Tmax)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float ndarray</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>xs</em>, <em>ilens</em>, <em>ys</em>, <em>calculate_attentions=False</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>compute loss for training</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs</strong> – For pytorch, batch of padded source sequences torch.Tensor (B, Tmax, idim)
For chainer, list of source sequences chainer.Variable</li>
<li><strong>ilens</strong> – batch of lengths of source sequences (B)
For pytorch, torch.Tensor
For chainer, list of int</li>
<li><strong>ys</strong> – For pytorch, batch of padded source sequences torch.Tensor (B, Lmax)
For chainer, list of source sequences chainer.Variable</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor for pytorch, chainer.Variable for chainer</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.make_attention_mask">
<code class="descname">make_attention_mask</code><span class="sig-paren">(</span><em>source_block</em>, <em>target_block</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.make_attention_mask" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.make_history_mask">
<code class="descname">make_history_mask</code><span class="sig-paren">(</span><em>block</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.make_history_mask" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.output_and_loss">
<code class="descname">output_and_loss</code><span class="sig-paren">(</span><em>concat_logit_block</em>, <em>t_block</em>, <em>batch</em>, <em>length</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.output_and_loss" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.recognize">
<code class="descname">recognize</code><span class="sig-paren">(</span><em>x_block</em>, <em>recog_args</em>, <em>char_list=None</em>, <em>rnnlm=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>ndarray</em>) – input acouctic feature (B, T, D) or (T, D)</li>
<li><strong>recog_args</strong> (<em>namespace</em>) – argment namespace contraining options</li>
<li><strong>char_list</strong> (<em>list</em>) – list of characters</li>
<li><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-best decoding results</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.E2E.reset_parameters">
<code class="descname">reset_parameters</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.E2E.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.PlotAttentionReport">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.e2e_asr_transformer.</code><code class="descname">PlotAttentionReport</code><span class="sig-paren">(</span><em>att_vis_fn</em>, <em>data</em>, <em>outdir</em>, <em>converter</em>, <em>transform</em>, <em>device</em>, <em>reverse=False</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.PlotAttentionReport" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="espnet-asr.html#espnet.asr.asr_utils.PlotAttentionReport" title="espnet.asr.asr_utils.PlotAttentionReport"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.asr.asr_utils.PlotAttentionReport</span></code></a></p>
<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.PlotAttentionReport.get_attention_weights">
<code class="descname">get_attention_weights</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.PlotAttentionReport.get_attention_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.PlotAttentionReport.log_attentions">
<code class="descname">log_attentions</code><span class="sig-paren">(</span><em>logger</em>, <em>step</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.PlotAttentionReport.log_attentions" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.VaswaniRule">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.e2e_asr_transformer.</code><code class="descname">VaswaniRule</code><span class="sig-paren">(</span><em>attr</em>, <em>d</em>, <em>warmup_steps=4000</em>, <em>init=None</em>, <em>target=None</em>, <em>optimizer=None</em>, <em>scale=1.0</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.VaswaniRule" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.training.extension.Extension</span></code></p>
<p>Trainer extension to shift an optimizer attribute magically by Vaswani.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd><p class="first">attr (str): Name of the attribute to shift.
rate (float): Rate of the exponential shift. This value is multiplied</p>
<blockquote>
<div>to the attribute at each call.</div></blockquote>
<dl class="last docutils">
<dt>init (float): Initial value of the attribute. If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the</dt>
<dd>extension extracts the attribute at the first call and uses it as
the initial value.</dd>
<dt>target (float): Target value of the attribute. If the attribute reaches</dt>
<dd>this value, the shift stops.</dd>
<dt>optimizer (~chainer.Optimizer): Target optimizer to adjust the</dt>
<dd>attribute. If it is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the main optimizer of the updater is
used.</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.VaswaniRule.initialize">
<code class="descname">initialize</code><span class="sig-paren">(</span><em>trainer</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.VaswaniRule.initialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Initializes up the trainer state.</p>
<p>This method is called before entering the training loop. An extension
that modifies the state of <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code> can
override this method to initialize it.</p>
<p>When the trainer has been restored from a snapshot, this method has to
recover an appropriate part of the state of the trainer.</p>
<p>For example, <code class="xref py py-class docutils literal notranslate"><span class="pre">ExponentialShift</span></code>
extension changes the optimizer’s hyperparameter at each invocation.
Note that the hyperparameter is not saved to the snapshot; it is the
responsibility of the extension to recover the hyperparameter.
The <code class="xref py py-class docutils literal notranslate"><span class="pre">ExponentialShift</span></code> extension
recovers it in its <code class="docutils literal notranslate"><span class="pre">initialize</span></code> method if it has been loaded from a
snapshot, or just setting the initial value otherwise.</p>
<dl class="docutils">
<dt>Args:</dt>
<dd>trainer (Trainer): Trainer object that runs the training loop.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.chainer_backend.e2e_asr_transformer.VaswaniRule.serialize">
<code class="descname">serialize</code><span class="sig-paren">(</span><em>serializer</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.e2e_asr_transformer.VaswaniRule.serialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Serializes the extension state.</p>
<p>It is called when a trainer that owns this extension is serialized. It
serializes nothing by default.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend-encoders">
<span id="id11"></span><h2>espnet.nets.chainer_backend.encoders<a class="headerlink" href="#espnet-nets-chainer-backend-encoders" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.encoders"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.encoders.Encoder">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.encoders.</code><code class="descname">Encoder</code><span class="sig-paren">(</span><em>etype</em>, <em>idim</em>, <em>elayers</em>, <em>eunits</em>, <em>eprojs</em>, <em>subsample</em>, <em>dropout</em>, <em>in_channel=1</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.encoders.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>Encoder network class</p>
<p>This is the example of docstring.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>etype</strong> (<em>str</em>) – type of encoder network</li>
<li><strong>idim</strong> (<em>int</em>) – number of dimensions of encoder network</li>
<li><strong>elayers</strong> (<em>int</em>) – number of layers of encoder network</li>
<li><strong>eunits</strong> (<em>int</em>) – number of lstm units of encoder network</li>
<li><strong>eprojs</strong> (<em>int</em>) – number of projection units of encoder network</li>
<li><strong>subsample</strong> (<em>np.ndarray</em>) – subsampling number e.g. 1_2_2_2_1</li>
<li><strong>dropout</strong> (<em>float</em>) – dropout rate</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.encoders.RNN">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.encoders.</code><code class="descname">RNN</code><span class="sig-paren">(</span><em>idim</em>, <em>elayers</em>, <em>cdim</em>, <em>hdim</em>, <em>dropout</em>, <em>typ='lstm'</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.encoders.RNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.encoders.RNNP">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.encoders.</code><code class="descname">RNNP</code><span class="sig-paren">(</span><em>idim</em>, <em>elayers</em>, <em>cdim</em>, <em>hdim</em>, <em>subsample</em>, <em>dropout</em>, <em>typ='blstm'</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.encoders.RNNP" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>RNN with projection layer module</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>idim</strong> (<em>int</em>) – dimension of inputs</li>
<li><strong>elayers</strong> (<em>int</em>) – number of encoder layers</li>
<li><strong>cdim</strong> (<em>int</em>) – number of rnn units (resulted in cdim * 2 if bidirectional)</li>
<li><strong>hdim</strong> (<em>int</em>) – number of projection units</li>
<li><strong>subsample</strong> (<em>np.ndarray</em>) – list of subsampling numbers</li>
<li><strong>dropout</strong> (<em>float</em>) – dropout rate</li>
<li><strong>typ</strong> (<em>str</em>) – The RNN type</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.encoders.VGG2L">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.encoders.</code><code class="descname">VGG2L</code><span class="sig-paren">(</span><em>in_channel=1</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.encoders.VGG2L" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.encoders.encoder_for">
<code class="descclassname">espnet.nets.chainer_backend.encoders.</code><code class="descname">encoder_for</code><span class="sig-paren">(</span><em>args</em>, <em>idim</em>, <em>subsample</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.encoders.encoder_for" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend-encoders-transformer">
<span id="id12"></span><h2>espnet.nets.chainer_backend.encoders_transformer<a class="headerlink" href="#espnet-nets-chainer-backend-encoders-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.encoders_transformer"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.encoders_transformer.Conv2dSubsampling">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.encoders_transformer.</code><code class="descname">Conv2dSubsampling</code><span class="sig-paren">(</span><em>channels</em>, <em>idim</em>, <em>dims</em>, <em>dropout=0.1</em>, <em>initialW=None</em>, <em>initial_bias=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.encoders_transformer.Conv2dSubsampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.encoders_transformer.Encoder">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.encoders_transformer.</code><code class="descname">Encoder</code><span class="sig-paren">(</span><em>input_type</em>, <em>idim</em>, <em>n_layers</em>, <em>n_units</em>, <em>d_units=0</em>, <em>h=8</em>, <em>dropout=0.1</em>, <em>initialW=None</em>, <em>initial_bias=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.encoders_transformer.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.encoders_transformer.EncoderLayer">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.encoders_transformer.</code><code class="descname">EncoderLayer</code><span class="sig-paren">(</span><em>n_units</em>, <em>d_units=0</em>, <em>h=8</em>, <em>dropout=0.1</em>, <em>initialW=None</em>, <em>initial_bias=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.encoders_transformer.EncoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.encoders_transformer.LinearSampling">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.encoders_transformer.</code><code class="descname">LinearSampling</code><span class="sig-paren">(</span><em>idim</em>, <em>dims</em>, <em>dropout=0.1</em>, <em>initialW=None</em>, <em>initial_bias=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.encoders_transformer.LinearSampling" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
</dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend-nets-utils">
<span id="id13"></span><h2>espnet.nets.chainer_backend.nets_utils<a class="headerlink" href="#espnet-nets-chainer-backend-nets-utils" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.nets_utils"></span><dl class="function">
<dt id="espnet.nets.chainer_backend.nets_utils.linear_tensor">
<code class="descclassname">espnet.nets.chainer_backend.nets_utils.</code><code class="descname">linear_tensor</code><span class="sig-paren">(</span><em>linear</em>, <em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.nets_utils.linear_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply linear matrix operation only for the last dimension of a tensor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>linear</strong> (<em>Link</em>) – Linear link (M x N matrix)</li>
<li><strong>x</strong> (<em>Variable</em>) – Tensor (D_1 x D_2 x … x M matrix)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">Tensor (D_1 x D_2 x … x N matrix)</p>
</td>
</tr>
</tbody>
</table>
<p>:rtype Variable</p>
</dd></dl>

</div>
<div class="section" id="espnet-nets-chainer-backend-nets-utils-transformer">
<span id="id14"></span><h2>espnet.nets.chainer_backend.nets_utils_transformer<a class="headerlink" href="#espnet-nets-chainer-backend-nets-utils-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.chainer_backend.nets_utils_transformer"></span><dl class="class">
<dt id="espnet.nets.chainer_backend.nets_utils_transformer.FeedForwardLayer">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.nets_utils_transformer.</code><code class="descname">FeedForwardLayer</code><span class="sig-paren">(</span><em>n_units</em>, <em>d_units=0</em>, <em>dropout=0.1</em>, <em>initialW=None</em>, <em>initial_bias=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.nets_utils_transformer.FeedForwardLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.nets_utils_transformer.LayerNorm">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.nets_utils_transformer.</code><code class="descname">LayerNorm</code><span class="sig-paren">(</span><em>dims</em>, <em>eps=1e-12</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.nets_utils_transformer.LayerNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.links.normalization.layer_normalization.LayerNormalization</span></code></p>
</dd></dl>

<dl class="class">
<dt id="espnet.nets.chainer_backend.nets_utils_transformer.PositionalEncoding">
<em class="property">class </em><code class="descclassname">espnet.nets.chainer_backend.nets_utils_transformer.</code><code class="descname">PositionalEncoding</code><span class="sig-paren">(</span><em>n_units</em>, <em>dropout=0.1</em>, <em>length=5000</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.nets_utils_transformer.PositionalEncoding" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.nets_utils_transformer.plot_multi_head_attention">
<code class="descclassname">espnet.nets.chainer_backend.nets_utils_transformer.</code><code class="descname">plot_multi_head_attention</code><span class="sig-paren">(</span><em>data</em>, <em>attn_dict</em>, <em>outdir</em>, <em>suffix='png'</em>, <em>savefn=&lt;function savefig&gt;</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.nets_utils_transformer.plot_multi_head_attention" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot multi head attentions</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<em>dict</em>) – utts info from json file</li>
<li><strong>torch.Tensor</strong><strong>] </strong><strong>attn_dict</strong> (<em>dict</em><em>[</em><em>str</em><em>,</em>) – multi head attention dict.
values should be torch.Tensor (head, input_length, output_length)</li>
<li><strong>outdir</strong> (<em>str</em>) – dir to save fig</li>
<li><strong>suffix</strong> (<em>str</em>) – filename suffix including image type (e.g., png)</li>
<li><strong>savefn</strong> – function to save</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.chainer_backend.nets_utils_transformer.savefig">
<code class="descclassname">espnet.nets.chainer_backend.nets_utils_transformer.</code><code class="descname">savefig</code><span class="sig-paren">(</span><em>plot</em>, <em>filename</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.chainer_backend.nets_utils_transformer.savefig" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="espnet-nets-ctc-prefix-score">
<span id="id15"></span><h2>espnet.nets.ctc_prefix_score<a class="headerlink" href="#espnet-nets-ctc-prefix-score" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.ctc_prefix_score"></span><dl class="class">
<dt id="espnet.nets.ctc_prefix_score.CTCPrefixScore">
<em class="property">class </em><code class="descclassname">espnet.nets.ctc_prefix_score.</code><code class="descname">CTCPrefixScore</code><span class="sig-paren">(</span><em>x</em>, <em>blank</em>, <em>eos</em>, <em>xp</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.ctc_prefix_score.CTCPrefixScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Compute CTC label sequence scores</p>
<p>which is based on Algorithm 2 in WATANABE et al.
“HYBRID CTC/ATTENTION ARCHITECTURE FOR END-TO-END SPEECH RECOGNITION,”
but extended to efficiently compute the probablities of multiple labels
simultaneously</p>
<dl class="method">
<dt id="espnet.nets.ctc_prefix_score.CTCPrefixScore.initial_state">
<code class="descname">initial_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.ctc_prefix_score.CTCPrefixScore.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain an initial CTC state</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">CTC state</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.ctc_prefix_score.CTCPrefixScoreTH">
<em class="property">class </em><code class="descclassname">espnet.nets.ctc_prefix_score.</code><code class="descname">CTCPrefixScoreTH</code><span class="sig-paren">(</span><em>x</em>, <em>blank</em>, <em>eos</em>, <em>beam</em>, <em>hlens</em>, <em>device_id</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.ctc_prefix_score.CTCPrefixScoreTH" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Batch processing of CTCPrefixScore</p>
<p>which is based on Algorithm 2 in WATANABE et al.
“HYBRID CTC/ATTENTION ARCHITECTURE FOR END-TO-END SPEECH RECOGNITION,”
but extended to efficiently compute the probablities of multiple labels
simultaneously</p>
<dl class="method">
<dt id="espnet.nets.ctc_prefix_score.CTCPrefixScoreTH.initial_state">
<code class="descname">initial_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.ctc_prefix_score.CTCPrefixScoreTH.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain an initial CTC state</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">CTC state</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.ctc_prefix_score.CTCPrefixScoreTH.to_cuda">
<code class="descname">to_cuda</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.ctc_prefix_score.CTCPrefixScoreTH.to_cuda" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet-nets-e2e-asr-common">
<span id="id16"></span><h2>espnet.nets.e2e_asr_common<a class="headerlink" href="#espnet-nets-e2e-asr-common" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.e2e_asr_common"></span><dl class="class">
<dt id="espnet.nets.e2e_asr_common.ErrorCalculator">
<em class="property">class </em><code class="descclassname">espnet.nets.e2e_asr_common.</code><code class="descname">ErrorCalculator</code><span class="sig-paren">(</span><em>char_list</em>, <em>sym_space</em>, <em>sym_blank</em>, <em>report_cer=False</em>, <em>report_wer=False</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.e2e_asr_common.ErrorCalculator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Calculate CER and WER for E2E_ASR and CTC models during training</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>y_hats</strong> – numpy array with predicted text</li>
<li><strong>y_pads</strong> – numpy array with true (target) text</li>
<li><strong>char_list</strong> – </li>
<li><strong>sym_space</strong> – </li>
<li><strong>sym_blank</strong> – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"></p>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="espnet.nets.e2e_asr_common.ErrorCalculator.calculate_cer">
<code class="descname">calculate_cer</code><span class="sig-paren">(</span><em>seqs_hat</em>, <em>seqs_true</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.e2e_asr_common.ErrorCalculator.calculate_cer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.e2e_asr_common.ErrorCalculator.calculate_cer_ctc">
<code class="descname">calculate_cer_ctc</code><span class="sig-paren">(</span><em>ys_hat</em>, <em>ys_pad</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.e2e_asr_common.ErrorCalculator.calculate_cer_ctc" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.e2e_asr_common.ErrorCalculator.calculate_wer">
<code class="descname">calculate_wer</code><span class="sig-paren">(</span><em>seqs_hat</em>, <em>seqs_true</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.e2e_asr_common.ErrorCalculator.calculate_wer" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.e2e_asr_common.ErrorCalculator.convert_to_char">
<code class="descname">convert_to_char</code><span class="sig-paren">(</span><em>ys_hat</em>, <em>ys_pad</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.e2e_asr_common.ErrorCalculator.convert_to_char" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.e2e_asr_common.end_detect">
<code class="descclassname">espnet.nets.e2e_asr_common.</code><code class="descname">end_detect</code><span class="sig-paren">(</span><em>ended_hyps</em>, <em>i</em>, <em>M=3</em>, <em>D_end=-10.0</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.e2e_asr_common.end_detect" title="Permalink to this definition">¶</a></dt>
<dd><p>End detection</p>
<p>desribed in Eq. (50) of S. Watanabe et al
“Hybrid CTC/Attention Architecture for End-to-End Speech Recognition”</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>ended_hyps</strong> – </li>
<li><strong>i</strong> – </li>
<li><strong>M</strong> – </li>
<li><strong>D_end</strong> – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.e2e_asr_common.get_vgg2l_odim">
<code class="descclassname">espnet.nets.e2e_asr_common.</code><code class="descname">get_vgg2l_odim</code><span class="sig-paren">(</span><em>idim</em>, <em>in_channel=3</em>, <em>out_channel=128</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.e2e_asr_common.get_vgg2l_odim" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet.nets.e2e_asr_common.label_smoothing_dist">
<code class="descclassname">espnet.nets.e2e_asr_common.</code><code class="descname">label_smoothing_dist</code><span class="sig-paren">(</span><em>odim</em>, <em>lsm_type</em>, <em>transcript=None</em>, <em>blank=0</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.e2e_asr_common.label_smoothing_dist" title="Permalink to this definition">¶</a></dt>
<dd><p>Obtain label distribution for loss smoothing</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>odim</strong> – </li>
<li><strong>lsm_type</strong> – </li>
<li><strong>blank</strong> – </li>
<li><strong>transcript</strong> – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="espnet-nets-pytorch-backend">
<span id="id17"></span><h2>espnet.nets.pytorch_backend<a class="headerlink" href="#espnet-nets-pytorch-backend" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend"></span></div>
<div class="section" id="espnet-nets-pytorch-backend-ctc">
<span id="id18"></span><h2>espnet.nets.pytorch_backend.ctc<a class="headerlink" href="#espnet-nets-pytorch-backend-ctc" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.ctc"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.ctc.CTC">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.ctc.</code><code class="descname">CTC</code><span class="sig-paren">(</span><em>odim</em>, <em>eprojs</em>, <em>dropout_rate</em>, <em>ctc_type='warpctc'</em>, <em>reduce=True</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>CTC module</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>odim</strong> (<em>int</em>) – dimension of outputs</li>
<li><strong>eprojs</strong> (<em>int</em>) – number of encoder projection units</li>
<li><strong>dropout_rate</strong> (<em>float</em>) – dropout rate (0.0 ~ 1.0)</li>
<li><strong>ctc_type</strong> (<em>str</em>) – builtin or warpctc</li>
<li><strong>reduce</strong> (<em>bool</em>) – reduce the CTC loss into a scalar</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.ctc.CTC.argmax">
<code class="descname">argmax</code><span class="sig-paren">(</span><em>hs_pad</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC.argmax" title="Permalink to this definition">¶</a></dt>
<dd><p>argmax of frame activations</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hs_pad</strong> (<em>torch.Tensor</em>) – 3d tensor (B, Tmax, eprojs)</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">argmax applied 2d tensor (B, Tmax)</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">torch.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.ctc.CTC.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>hs_pad</em>, <em>hlens</em>, <em>ys_pad</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>CTC forward</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>hs_pad</strong> (<em>torch.Tensor</em>) – batch of padded hidden state sequences (B, Tmax, D)</li>
<li><strong>hlens</strong> (<em>torch.Tensor</em>) – batch of lengths of hidden state sequences (B)</li>
<li><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, Lmax)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">ctc loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.ctc.CTC.log_softmax">
<code class="descname">log_softmax</code><span class="sig-paren">(</span><em>hs_pad</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC.log_softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>log_softmax of frame activations</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>hs_pad</strong> (<em>torch.Tensor</em>) – 3d tensor (B, Tmax, eprojs)</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">log softmax applied 3d tensor (B, Tmax, odim)</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">torch.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.ctc.CTC.loss_fn">
<code class="descname">loss_fn</code><span class="sig-paren">(</span><em>th_pred</em>, <em>th_target</em>, <em>th_ilen</em>, <em>th_olen</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.CTC.loss_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.ctc.ctc_for">
<code class="descclassname">espnet.nets.pytorch_backend.ctc.</code><code class="descname">ctc_for</code><span class="sig-paren">(</span><em>args</em>, <em>odim</em>, <em>reduce=True</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.ctc.ctc_for" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the CTC module for the given args and output dimension</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>args</strong> (<em>Namespace</em>) – the program args</td>
</tr>
</tbody>
</table>
<p>:param int odim : The output dimension
:param bool reduce : return the CTC loss in a scalar
:return: the corresponding CTC module</p>
</dd></dl>

</div>
<div class="section" id="espnet-nets-pytorch-backend-e2e-asr">
<span id="id19"></span><h2>espnet.nets.pytorch_backend.e2e_asr<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-asr" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_asr"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_asr.</code><code class="descname">E2E</code><span class="sig-paren">(</span><em>idim</em>, <em>odim</em>, <em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>idim</strong> (<em>int</em>) – dimension of inputs</li>
<li><strong>odim</strong> (<em>int</em>) – dimension of outputs</li>
<li><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.calculate_all_attentions">
<code class="descname">calculate_all_attentions</code><span class="sig-paren">(</span><em>xs_pad</em>, <em>ilens</em>, <em>ys_pad</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</li>
<li><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, Lmax)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">attention weights with the following shape,
1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
2) other case =&gt; attention weights (B, Lmax, Tmax).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float ndarray</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.enhance">
<code class="descname">enhance</code><span class="sig-paren">(</span><em>xs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.enhance" title="Permalink to this definition">¶</a></dt>
<dd><p>Forwarding only the frontend stage</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>xs</strong> (<em>ndarray</em>) – input acoustic feature (T, C, F)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>xs_pad</em>, <em>ilens</em>, <em>ys_pad</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</li>
<li><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, Lmax)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">ctc loass value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">attention loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">accuracy in attention decoder</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.init_like_chainer">
<code class="descname">init_like_chainer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.init_like_chainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize weight like chainer</p>
<p>chainer basically uses LeCun way: W ~ Normal(0, fan_in ** -0.5), b = 0
pytorch basically uses W, b ~ Uniform(-fan_in**-0.5, fan_in**-0.5)</p>
<p>however, there are two exceptions as far as I know.
- EmbedID.W ~ Normal(0, 1)
- LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.recognize">
<code class="descname">recognize</code><span class="sig-paren">(</span><em>x</em>, <em>recog_args</em>, <em>char_list</em>, <em>rnnlm=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>ndarray</em>) – input acoustic feature (T, D)</li>
<li><strong>recog_args</strong> (<em>Namespace</em>) – argument Namespace containing options</li>
<li><strong>char_list</strong> (<em>list</em>) – list of characters</li>
<li><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-best decoding results</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.recognize_batch">
<code class="descname">recognize_batch</code><span class="sig-paren">(</span><em>xs</em>, <em>recog_args</em>, <em>char_list</em>, <em>rnnlm=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.recognize_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs</strong> (<em>list</em>) – list of input acoustic feature arrays [(T_1, D), (T_2, D), …]</li>
<li><strong>recog_args</strong> (<em>Namespace</em>) – argument Namespace containing options</li>
<li><strong>char_list</strong> (<em>list</em>) – list of characters</li>
<li><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-best decoding results</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.E2E.subsample_frames">
<code class="descname">subsample_frames</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.E2E.subsample_frames" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr.Reporter">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_asr.</code><code class="descname">Reporter</code><span class="sig-paren">(</span><em>**links</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.Reporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>A chainer reporter wrapper</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr.Reporter.report">
<code class="descname">report</code><span class="sig-paren">(</span><em>loss_ctc</em>, <em>loss_att</em>, <em>acc</em>, <em>cer_ctc</em>, <em>cer</em>, <em>wer</em>, <em>mtl_loss</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr.Reporter.report" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet-nets-pytorch-backend-e2e-asr-mix">
<span id="id20"></span><h2>espnet.nets.pytorch_backend.e2e_asr_mix<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-asr-mix" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_asr_mix"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_asr_mix.</code><code class="descname">E2E</code><span class="sig-paren">(</span><em>idim</em>, <em>odim</em>, <em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>E2E module</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>idim</strong> (<em>int</em>) – dimension of inputs</li>
<li><strong>odim</strong> (<em>int</em>) – dimension of outputs</li>
<li><strong>args</strong> (<em>Namespace</em>) – argument Namespace containing options</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.calculate_all_attentions">
<code class="descname">calculate_all_attentions</code><span class="sig-paren">(</span><em>xs_pad</em>, <em>ilens</em>, <em>ys_pad_sd</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</li>
<li><strong>ys_pad_sd</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, num_spkrs, Lmax)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">attention weights with the following shape,
1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
2) other case =&gt; attention weights (B, Lmax, Tmax).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float ndarray</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>xs_pad</em>, <em>ilens</em>, <em>ys_pad_sd</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</li>
<li><strong>ys_pad_sd</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, num_spkrs, Lmax)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">ctc loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">attention loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">accuracy in attention decoder</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.init_like_chainer">
<code class="descname">init_like_chainer</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.init_like_chainer" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize weight like chainer</p>
<p>chainer basically uses LeCun way: W ~ Normal(0, fan_in ** -0.5), b = 0
pytorch basically uses W, b ~ Uniform(-fan_in**-0.5, fan_in**-0.5)</p>
<p>however, there are two exceptions as far as I know.
- EmbedID.W ~ Normal(0, 1)
- LSTM.upward.b[forget_gate_range] = 1 (but not used in NStepLSTM)</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.recognize">
<code class="descname">recognize</code><span class="sig-paren">(</span><em>x</em>, <em>recog_args</em>, <em>char_list</em>, <em>rnnlm=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>ndarray</em>) – input acoustic feature (T, D)</li>
<li><strong>recog_args</strong> (<em>Namespace</em>) – argument Namespace containing options</li>
<li><strong>char_list</strong> (<em>list</em>) – list of characters</li>
<li><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-best decoding results</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.E2E.recognize_batch">
<code class="descname">recognize_batch</code><span class="sig-paren">(</span><em>xs</em>, <em>recog_args</em>, <em>char_list</em>, <em>rnnlm=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.E2E.recognize_batch" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E beam search</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs</strong> (<em>ndarray</em>) – input acoustic feature (T, D)</li>
<li><strong>recog_args</strong> (<em>Namespace</em>) – argument Namespace containing options</li>
<li><strong>char_list</strong> (<em>list</em>) – list of characters</li>
<li><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-best decoding results</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.Encoder">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_asr_mix.</code><code class="descname">Encoder</code><span class="sig-paren">(</span><em>etype</em>, <em>idim</em>, <em>elayers_sd</em>, <em>elayers_rec</em>, <em>eunits</em>, <em>eprojs</em>, <em>subsample</em>, <em>dropout</em>, <em>num_spkrs=2</em>, <em>in_channel=1</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.Encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encoder module</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>etype</strong> (<em>str</em>) – type of encoder network</li>
<li><strong>idim</strong> (<em>int</em>) – number of dimensions of encoder network</li>
<li><strong>elayers_sd</strong> (<em>int</em>) – number of layers of speaker differentiate part in encoder network</li>
<li><strong>elayers_rec</strong> (<em>int</em>) – number of layers of shared recognition part in encoder network</li>
<li><strong>eunits</strong> (<em>int</em>) – number of lstm units of encoder network</li>
<li><strong>eprojs</strong> (<em>int</em>) – number of projection units of encoder network</li>
<li><strong>subsample</strong> (<em>np.ndarray</em>) – list of subsampling numbers</li>
<li><strong>dropout</strong> (<em>float</em>) – dropout rate</li>
<li><strong>in_channel</strong> (<em>int</em>) – number of input channels</li>
<li><strong>num_spkrs</strong> (<em>int</em>) – number of number of speakers</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.Encoder.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>xs_pad</em>, <em>ilens</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.Encoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Encoder forward</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, D)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">list: batch of hidden state sequences [num_spkrs x (B, Tmax, eprojs)]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.PIT">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_asr_mix.</code><code class="descname">PIT</code><span class="sig-paren">(</span><em>num_spkrs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.PIT" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Permutation Invariant Training (PIT) module</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>num_spkrs</strong> (<em>int</em>) – number of speakers for PIT process (2 or 3)</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.PIT.min_pit_sample">
<code class="descname">min_pit_sample</code><span class="sig-paren">(</span><em>loss</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.PIT.min_pit_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>PIT min_pit_sample</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>torch.Tensor loss</strong> (<em>1-D</em>) – list of losses for one sample,
including [h1r1, h1r2, h2r1, h2r2] or [h1r1, h1r2, h1r3, h2r1, h2r2, h2r3, h3r1, h3r2, h3r3]</td>
</tr>
</tbody>
</table>
<p>:return min_loss
:rtype torch.Tensor (1)
:return permutation
:rtype List: len=2</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.PIT.pit_process">
<code class="descname">pit_process</code><span class="sig-paren">(</span><em>losses</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.PIT.pit_process" title="Permalink to this definition">¶</a></dt>
<dd><p>PIT pit_process</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>losses</strong> (<em>torch.Tensor</em>) – losses (B, 1|4|9)</td>
</tr>
</tbody>
</table>
<p>:return pit_loss
:rtype torch.Tensor (B)
:return permutation
:rtype torch.LongTensor (B, 1|2|3)</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.Reporter">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_asr_mix.</code><code class="descname">Reporter</code><span class="sig-paren">(</span><em>**links</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.Reporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<p>A chainer reporter wrapper</p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.Reporter.report">
<code class="descname">report</code><span class="sig-paren">(</span><em>loss_ctc</em>, <em>loss_att</em>, <em>acc</em>, <em>cer</em>, <em>wer</em>, <em>mtl_loss</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.Reporter.report" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.e2e_asr_mix.encoder_for">
<code class="descclassname">espnet.nets.pytorch_backend.e2e_asr_mix.</code><code class="descname">encoder_for</code><span class="sig-paren">(</span><em>args</em>, <em>idim</em>, <em>subsample</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_mix.encoder_for" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="espnet-nets-pytorch-backend-e2e-asr-transformer">
<span id="id21"></span><h2>espnet.nets.pytorch_backend.e2e_asr_transformer<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-asr-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_asr_transformer"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_asr_transformer.</code><code class="descname">E2E</code><span class="sig-paren">(</span><em>idim</em>, <em>odim</em>, <em>args</em>, <em>ignore_id=-1</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.asr_interface.ASRInterface" title="espnet.nets.asr_interface.ASRInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.asr_interface.ASRInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="staticmethod">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.add_arguments">
<em class="property">static </em><code class="descname">add_arguments</code><span class="sig-paren">(</span><em>parser</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.add_sos_eos">
<code class="descname">add_sos_eos</code><span class="sig-paren">(</span><em>ys_pad</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.add_sos_eos" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.attention_plot_class">
<code class="descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.calculate_all_attentions">
<code class="descname">calculate_all_attentions</code><span class="sig-paren">(</span><em>xs_pad</em>, <em>ilens</em>, <em>ys_pad</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E attention calculation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded input sequences (B, Tmax, idim)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of input sequences (B)</li>
<li><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded character id sequence tensor (B, Lmax)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">attention weights with the following shape,
1) multi-head case =&gt; attention weights (B, H, Lmax, Tmax),
2) other case =&gt; attention weights (B, Lmax, Tmax).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float ndarray</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>xs_pad</em>, <em>ilens</em>, <em>ys_pad</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>E2E forward</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs_pad</strong> (<em>torch.Tensor</em>) – batch of padded source sequences (B, Tmax, idim)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of lengths of source sequences (B)</li>
<li><strong>ys_pad</strong> (<em>torch.Tensor</em>) – batch of padded target sequences (B, Lmax)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">ctc loass value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">attention loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">accuracy in attention decoder</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.recognize">
<code class="descname">recognize</code><span class="sig-paren">(</span><em>feat</em>, <em>recog_args</em>, <em>char_list=None</em>, <em>rnnlm=None</em>, <em>use_jit=False</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.recognize" title="Permalink to this definition">¶</a></dt>
<dd><p>recognize feat</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>ndnarray</em>) – input acouctic feature (B, T, D) or (T, D)</li>
<li><strong>recog_args</strong> (<em>namespace</em>) – argment namespace contraining options</li>
<li><strong>char_list</strong> (<em>list</em>) – list of characters</li>
<li><strong>rnnlm</strong> (<em>torch.nn.Module</em>) – language model module</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">N-best decoding results</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list</p>
</td>
</tr>
</tbody>
</table>
<p>TODO(karita): do not recompute previous attention for faster decoding</p>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.reset_parameters">
<code class="descname">reset_parameters</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.target_mask">
<code class="descname">target_mask</code><span class="sig-paren">(</span><em>ys_in_pad</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.E2E.target_mask" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.e2e_asr_transformer.subsequent_mask">
<code class="descclassname">espnet.nets.pytorch_backend.e2e_asr_transformer.</code><code class="descname">subsequent_mask</code><span class="sig-paren">(</span><em>size</em>, <em>device='cpu'</em>, <em>dtype=torch.uint8</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_asr_transformer.subsequent_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Create mask for subsequent steps (1, size, size)</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>size</strong> (<em>int</em>) – size of mask</li>
<li><strong>device</strong> (<em>str</em>) – “cpu” or “cuda” or torch.Tensor.device</li>
<li><strong>dtype</strong> (<em>torch.dtype</em>) – result dtype</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">subsequent_mask</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="go">[[1, 0, 0],</span>
<span class="go"> [1, 1, 0],</span>
<span class="go"> [1, 1, 1]]</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="espnet-nets-pytorch-backend-e2e-tts-tacotron2">
<span id="id22"></span><h2>espnet.nets.pytorch_backend.e2e_tts_tacotron2<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-tts-tacotron2" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_tts_tacotron2"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.CBHGLoss">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_tts_tacotron2.</code><code class="descname">CBHGLoss</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.CBHGLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Loss function for CBHG module</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>args</strong> (<em>Namespace</em>) – argments containing following attributes
(bool) use_masking: whether to mask padded part in loss calculation</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.CBHGLoss.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>cbhg_outs</em>, <em>spcs</em>, <em>olens</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.CBHGLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>CBHG loss forward computation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>cbhg_outs</strong> (<em>torch.Tensor</em>) – cbhg outputs (B, Lmax, spc_dim)</li>
<li><strong>before_outs</strong> (<em>torch.Tensor</em>) – groundtruth of spectrogram (B, Lmax, spc_dim)</li>
<li><strong>olens</strong> (<em>list</em>) – batch of the lengths of each target (B)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">l1 loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">mean square error loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_tts_tacotron2.</code><code class="descname">GuidedAttentionLoss</code><span class="sig-paren">(</span><em>sigma=0.4</em>, <em>reset_always=True</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Guided attention loss function</p>
<dl class="docutils">
<dt>Reference:</dt>
<dd>Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention
(<a class="reference external" href="https://arxiv.org/abs/1710.08969">https://arxiv.org/abs/1710.08969</a>)</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sigma</strong> (<em>float</em>) – standard deviation to control how close attention to a diagonal</li>
<li><strong>reset_always</strong> (<em>bool</em>) – whether to always reset masks</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>att_ws</em>, <em>ilens</em>, <em>olens</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>GuidedAttentionLoss forward calculation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>att_ws</strong> (<em>torch.Tenosr</em>) – batch of attention weights (B, T_max_out, T_max_in)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of input lenghts (B,)</li>
<li><strong>olens</strong> (<em>torch.Tensor</em>) – batch of output lenghts (B,)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2">Return torch.tensor:</th></tr>
<tr class="field-even field"><td>&#160;</td><td class="field-body"><p class="first last">guided attention loss value</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss.reset_masks">
<code class="descname">reset_masks</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss.reset_masks" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_tts_tacotron2.</code><code class="descname">Tacotron2</code><span class="sig-paren">(</span><em>idim</em>, <em>odim</em>, <em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.tts_interface.TTSInterface" title="espnet.nets.tts_interface.TTSInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.tts_interface.TTSInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Tacotron2 based Seq2Seq converts chars to features</p>
<dl class="docutils">
<dt>Reference:</dt>
<dd>Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions
(<a class="reference external" href="https://arxiv.org/abs/1712.05884">https://arxiv.org/abs/1712.05884</a>)</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>idim</strong> (<em>int</em>) – dimension of the inputs</li>
<li><strong>odim</strong> (<em>int</em>) – dimension of the outputs</li>
<li><strong>args</strong> (<em>Namespace</em>) – argments containing following attributes
(int) spk_embed_dim: dimension of the speaker embedding
(int) embed_dim: dimension of character embedding
(int) elayers: the number of encoder blstm layers
(int) eunits: the number of encoder blstm units
(int) econv_layers: the number of encoder conv layers
(int) econv_filts: the number of encoder conv filter size
(int) econv_chans: the number of encoder conv filter channels
(int) dlayers: the number of decoder lstm layers
(int) dunits: the number of decoder lstm units
(int) prenet_layers: the number of prenet layers
(int) prenet_units: the number of prenet units
(int) postnet_layers: the number of postnet layers
(int) postnet_filts: the number of postnet filter size
(int) postnet_chans: the number of postnet filter channels
(str) output_activation: the name of activation function for outputs
(int) adim: the number of dimension of mlp in attention
(int) aconv_chans: the number of attention conv filter channels
(int) aconv_filts: the number of attention conv filter size
(bool) cumulate_att_w: whether to cumulate previous attention weight
(bool) use_batch_norm: whether to use batch normalization
(bool) use_concate: whether to concatenate encoder embedding with decoder lstm outputs
(float) dropout_rate: dropout rate
(float) zoneout_rate: zoneout rate
(int) reduction_factor: reduction factor
(bool) use_cbhg: whether to use CBHG module
(int) cbhg_conv_bank_layers: the number of convoluional banks in CBHG
(int) cbhg_conv_bank_chans: the number of channels of convolutional bank in CBHG
(int) cbhg_proj_filts: the number of filter size of projection layeri in CBHG
(int) cbhg_proj_chans: the number of channels of projection layer in CBHG
(int) cbhg_highway_layers: the number of layers of highway network in CBHG
(int) cbhg_highway_units: the number of units of highway network in CBHG
(int) cbhg_gru_units: the number of units of GRU in CBHG
(bool) use_masking: whether to mask padded part in loss calculation
(float) bce_pos_weight: weight of positive sample of stop token (only for use_masking=True)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="staticmethod">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.add_arguments">
<em class="property">static </em><code class="descname">add_arguments</code><span class="sig-paren">(</span><em>parser</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.base_plot_keys">
<code class="descname">base_plot_keys</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.base_plot_keys" title="Permalink to this definition">¶</a></dt>
<dd><p>base key names to plot during training. keys should match what <cite>chainer.reporter</cite> reports</p>
<p>if you add the key <cite>loss</cite>, the reporter will report <cite>main/loss</cite> and <cite>validation/main/loss</cite> values.
also <cite>loss.png</cite> will be created as a figure visulizing <cite>main/loss</cite> and <cite>validation/main/loss</cite> values.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name" colspan="2">Rtype list[str] plot_keys:</th></tr>
<tr class="field-odd field"><td>&#160;</td><td class="field-body">base keys to plot during training</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.calculate_all_attentions">
<code class="descname">calculate_all_attentions</code><span class="sig-paren">(</span><em>xs</em>, <em>ilens</em>, <em>ys</em>, <em>spembs=None</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Tacotron2 attention weight computation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs</strong> (<em>torch.Tensor</em>) – batch of padded character ids (B, Tmax)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – list of lengths of each input batch (B)</li>
<li><strong>ys</strong> (<em>torch.Tensor</em>) – batch of padded target features (B, Lmax, odim)</li>
<li><strong>spembs</strong> (<em>torch.Tensor</em>) – batch of speaker embedding vector (B, spk_embed_dim)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">attention weights (B, Lmax, Tmax)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">numpy array</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>xs</em>, <em>ilens</em>, <em>ys</em>, <em>labels</em>, <em>olens</em>, <em>spembs=None</em>, <em>spcs=None</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Tacotron2 forward computation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs</strong> (<em>torch.Tensor</em>) – batch of padded character ids (B, Tmax)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – list of lengths of each input batch (B)</li>
<li><strong>ys</strong> (<em>torch.Tensor</em>) – batch of padded target features (B, Lmax, odim)</li>
<li><strong>olens</strong> (<em>torch.Tensor</em>) – batch of the lengths of each target (B)</li>
<li><strong>spembs</strong> (<em>torch.Tensor</em>) – batch of speaker embedding vector (B, spk_embed_dim)</li>
<li><strong>spcs</strong> (<em>torch.Tensor</em>) – batch of groundtruth spectrogram (B, Lmax, spc_dim)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.inference">
<code class="descname">inference</code><span class="sig-paren">(</span><em>x</em>, <em>inference_args</em>, <em>spemb=None</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates the sequence of features given the sequences of characters</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>torch.Tensor</em>) – the sequence of characters (T)</li>
<li><strong>inference_args</strong> (<em>Namespace</em>) – argments containing following attributes
(float) threshold: threshold in inference
(float) minlenratio: minimum length ratio in inference
(float) maxlenratio: maximum length ratio in inference</li>
<li><strong>spemb</strong> (<em>torch.Tensor</em>) – speaker embedding vector (spk_embed_dim)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the sequence of features (L, odim)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the sequence of stop probabilities (L)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the sequence of attention weight (L, T)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_tts_tacotron2.</code><code class="descname">Tacotron2Loss</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Tacotron2 loss function</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>args</strong> (<em>Namespace</em>) – argments containing following attributes
(bool) use_masking: whether to mask padded part in loss calculation
(float) bce_pos_weight: weight of positive sample of stop token (only for use_masking=True)</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>after_outs</em>, <em>before_outs</em>, <em>logits</em>, <em>ys</em>, <em>labels</em>, <em>olens</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.Tacotron2Loss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Tacotron2 loss forward computation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>after_outs</strong> (<em>torch.Tensor</em>) – outputs with postnets (B, Lmax, odim)</li>
<li><strong>before_outs</strong> (<em>torch.Tensor</em>) – outputs without postnets (B, Lmax, odim)</li>
<li><strong>logits</strong> (<em>torch.Tensor</em>) – stop logits (B, Lmax)</li>
<li><strong>ys</strong> (<em>torch.Tensor</em>) – batch of padded target features (B, Lmax, odim)</li>
<li><strong>labels</strong> (<em>torch.Tensor</em>) – batch of the sequences of stop token labels (B, Lmax)</li>
<li><strong>olens</strong> (<em>list</em>) – batch of the lengths of each target (B)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">l1 loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">mean square error loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">binary cross entropy loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.e2e_tts_tacotron2.make_non_pad_mask">
<code class="descclassname">espnet.nets.pytorch_backend.e2e_tts_tacotron2.</code><code class="descname">make_non_pad_mask</code><span class="sig-paren">(</span><em>lengths</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.make_non_pad_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to make tensor mask containing indices of the non-padded part</p>
<dl class="docutils">
<dt>e.g.: lengths = [5, 3, 2]</dt>
<dd><dl class="first last docutils">
<dt>mask = [[1, 1, 1, 1 ,1],</dt>
<dd>[1, 1, 1, 0, 0],
[1, 1, 0, 0, 0]]</dd>
</dl>
</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>lengths</strong> (<em>list</em>) – list of lengths (B)</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">mask tensor containing indices of non-padded part (B, Tmax)</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">torch.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="espnet-nets-pytorch-backend-e2e-tts-transformer">
<span id="id23"></span><h2>espnet.nets.pytorch_backend.e2e_tts_transformer<a class="headerlink" href="#espnet-nets-pytorch-backend-e2e-tts-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.e2e_tts_transformer"></span><dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_tts_transformer.</code><code class="descname">GuidedMultiHeadAttentionLoss</code><span class="sig-paren">(</span><em>sigma=0.4</em>, <em>reset_always=True</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss" title="espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.e2e_tts_tacotron2.GuidedAttentionLoss</span></code></a></p>
<p>Guided attention loss for multi head attention</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sigma</strong> (<em>float</em>) – standard deviation to control how close attention to a diagonal</li>
<li><strong>reset_always</strong> (<em>bool</em>) – whether to always reset mask</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>att_ws</em>, <em>ilens</em>, <em>olens</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.GuidedMultiHeadAttentionLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate guided attention loss for multi head attention</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>att_ws</strong> (<em>torch.Tenosr</em>) – attention weights (B, H, T_max_out, T_max_in)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – batch of input lenghts (B,)</li>
<li><strong>olens</strong> (<em>torch.Tensor</em>) – batch of output lenghts (B,)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name" colspan="2">Return torch.tensor:</th></tr>
<tr class="field-even field"><td>&#160;</td><td class="field-body"><p class="first last">guided attention loss value</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.TTSPlot">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_tts_transformer.</code><code class="descname">TTSPlot</code><span class="sig-paren">(</span><em>att_vis_fn</em>, <em>data</em>, <em>outdir</em>, <em>converter</em>, <em>transform</em>, <em>device</em>, <em>reverse=False</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.TTSPlot" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.pytorch_backend.transformer.plot.PlotAttentionReport</span></code></p>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.TTSPlot.plotfn">
<code class="descname">plotfn</code><span class="sig-paren">(</span><em>data</em>, <em>attn_dict</em>, <em>outdir</em>, <em>suffix='png'</em>, <em>savefn=None</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.TTSPlot.plotfn" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot multi head attentions</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data</strong> (<em>dict</em>) – utts info from json file</li>
<li><strong>torch.Tensor</strong><strong>] </strong><strong>attn_dict</strong> (<em>dict</em><em>[</em><em>str</em><em>,</em>) – multi head attention dict.
values should be torch.Tensor (head, input_length, output_length)</li>
<li><strong>outdir</strong> (<em>str</em>) – dir to save fig</li>
<li><strong>suffix</strong> (<em>str</em>) – filename suffix including image type (e.g., png)</li>
<li><strong>savefn</strong> – function to save</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_tts_transformer.</code><code class="descname">Transformer</code><span class="sig-paren">(</span><em>idim</em>, <em>odim</em>, <em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#espnet.nets.tts_interface.TTSInterface" title="espnet.nets.tts_interface.TTSInterface"><code class="xref py py-class docutils literal notranslate"><span class="pre">espnet.nets.tts_interface.TTSInterface</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Text-to-Speech Transformer</p>
<dl class="docutils">
<dt>Reference:</dt>
<dd>Neural Speech Synthesis with Transformer Network
(<a class="reference external" href="https://arxiv.org/pdf/1809.08895.pdf">https://arxiv.org/pdf/1809.08895.pdf</a>)</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>idim</strong> (<em>int</em>) – dimension of the inputs</li>
<li><strong>odim</strong> (<em>int</em>) – dimension of the outputs</li>
<li><strong>args</strong> (<em>Namespace</em>) – argments containing following attributes
(int) embed_dim: dimension of character embedding
(int) eprenet_conv_layers: number of encoder prenet convolution layers
(int) eprenet_conv_chans: number of encoder prenet convolution channels
(int) eprenet_conv_filts: filter size of encoder prenet convolution
(int) dprenet_layers: number of decoder prenet layers
(int) dprenet_units: number of decoder prenet hidden units
(int) elayers: number of encoder layers
(int) eunits: number of encoder hidden units
(int) adim: number of attention transformation dimensions
(int) aheads: number of heads for multi head attention
(int) dlayers: number of decoder layers
(int) dunits: number of decoder hidden units
(int) postnet_layers: number of postnet layers
(int) postnet_chans: number of postnet channels
(int) postnet_filts: filter size of postnet
(bool) use_scaled_pos_enc: whether to use trainable scaled positional encoding instead of the fixed scale one
(bool) use_batch_norm: whether to use batch normalization in encoder prenet
(bool) encoder_normalize_before: whether to perform layer normalization before encoder block
(bool) decoder_normalize_before: whether to perform layer normalization before decoder block
(bool) encoder_concat_after: whether to concatenate attention layer’s input and output in encoder
(bool) decoder_concat_after: whether to concatenate attention layer’s input and output in decoder
(int) reduction_factor: reduction factor
(float) transformer_init: how to initialize transformer parameters
(float) transformer_lr: initial value of learning rate
(int) transformer_warmup_steps: optimizer warmup steps
(float) transformer_enc_dropout_rate: dropout rate in encoder except for attention and positional encoding
(float) transformer_enc_positional_dropout_rate: dropout rate after encoder positional encoding
(float) transformer_enc_attn_dropout_rate: dropout rate in encoder self-attention module
(float) transformer_dec_dropout_rate: dropout rate in decoder except for attention and positional encoding
(float) transformer_dec_positional_dropout_rate:  dropout rate after decoder positional encoding
(float) transformer_dec_attn_dropout_rate: dropout rate in deocoder self-attention module
(float) transformer_enc_dec_attn_dropout_rate: dropout rate in encoder-deocoder attention module
(float) eprenet_dropout_rate: dropout rate in encoder prenet
(float) dprenet_dropout_rate: dropout rate in decoder prenet
(float) postnet_dropout_rate: dropout rate in postnet
(bool) use_masking: whether to use masking in calculation of loss
(float) bce_pos_weight: positive sample weight in bce calculation (only for use_masking=true)
(str) loss_type: how to calculate loss
(bool) use_guided_attn_loss: whether to use guided attention loss
(int) num_heads_applied_guided_attn: number of heads in each layer to be applied guided attention loss
(int) num_layers_applied_guided_attn: number of layers to be applied guided attention loss
(list) modules_applied_guided_attn: list of module names to be applied guided attention loss</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="staticmethod">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.add_arguments">
<em class="property">static </em><code class="descname">add_arguments</code><span class="sig-paren">(</span><em>parser</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.attention_plot_class">
<code class="descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.base_plot_keys">
<code class="descname">base_plot_keys</code><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.base_plot_keys" title="Permalink to this definition">¶</a></dt>
<dd><p>base key names to plot during training. keys should match what <cite>chainer.reporter</cite> reports</p>
<p>if you add the key <cite>loss</cite>, the reporter will report <cite>main/loss</cite> and <cite>validation/main/loss</cite> values.
also <cite>loss.png</cite> will be created as a figure visulizing <cite>main/loss</cite> and <cite>validation/main/loss</cite> values.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name" colspan="2">Rtype list[str] plot_keys:</th></tr>
<tr class="field-odd field"><td>&#160;</td><td class="field-body">base keys to plot during training</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.calculate_all_attentions">
<code class="descname">calculate_all_attentions</code><span class="sig-paren">(</span><em>xs</em>, <em>ilens</em>, <em>ys</em>, <em>olens</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate attention weights of all of the layers</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs</strong> (<em>torch.Tensor</em>) – batch of padded character ids (B, Tmax)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – list of lengths of each input batch (B)</li>
<li><strong>ys</strong> (<em>torch.Tensor</em>) – batch of padded target features (B, Lmax, odim)</li>
<li><strong>ilens</strong> – list of lengths of each output batch (B)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">attention weights dict</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">dict</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>xs</em>, <em>ilens</em>, <em>ys</em>, <em>labels</em>, <em>olens</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate forward propagation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs</strong> (<em>torch.Tensor</em>) – batch of padded character ids (B, Tmax)</li>
<li><strong>ilens</strong> (<em>torch.Tensor</em>) – list of lengths of each input batch (B)</li>
<li><strong>ys</strong> (<em>torch.Tensor</em>) – batch of padded target features (B, Lmax, odim)</li>
<li><strong>olens</strong> (<em>torch.Tensor</em>) – batch of the lengths of each target (B)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.inference">
<code class="descname">inference</code><span class="sig-paren">(</span><em>x</em>, <em>inference_args</em>, <em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.Transformer.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates the sequence of features from given a sequences of characters</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>x</strong> (<em>torch.Tensor</em>) – the sequence of character ids (T)</li>
<li><strong>inference_args</strong> (<em>Namespace</em>) – argments containing following attributes
(float) threshold: threshold in inference
(float) minlenratio: minimum length ratio in inference
(float) maxlenratio: maximum length ratio in inference</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the sequence of stop probabilities (L)</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.TransformerLoss">
<em class="property">class </em><code class="descclassname">espnet.nets.pytorch_backend.e2e_tts_transformer.</code><code class="descname">TransformerLoss</code><span class="sig-paren">(</span><em>args</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.TransformerLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Transformer loss function</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>args</strong> (<em>Namespace</em>) – argments containing following attributes
(bool) use_masking: whether to mask padded part in loss calculation
(float) bce_pos_weight: weight of positive sample of stop token (only for use_masking=True)</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="espnet.nets.pytorch_backend.e2e_tts_transformer.TransformerLoss.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>after_outs</em>, <em>before_outs</em>, <em>logits</em>, <em>ys</em>, <em>labels</em>, <em>olens</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.e2e_tts_transformer.TransformerLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate trasnformer loss</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>after_outs</strong> (<em>torch.Tensor</em>) – outputs with postnets (B, Lmax, odim)</li>
<li><strong>before_outs</strong> (<em>torch.Tensor</em>) – outputs without postnets (B, Lmax, odim)</li>
<li><strong>logits</strong> (<em>torch.Tensor</em>) – stop logits (B, Lmax)</li>
<li><strong>ys</strong> (<em>torch.Tensor</em>) – batch of padded target features (B, Lmax, odim)</li>
<li><strong>labels</strong> (<em>torch.Tensor</em>) – batch of the sequences of stop token labels (B, Lmax)</li>
<li><strong>olens</strong> (<em>list</em>) – batch of the lengths of each target (B)</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">l1 loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">mean square error loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first">torch.Tensor</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">binary cross entropy loss value</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="espnet-nets-pytorch-backend-frontends">
<span id="id24"></span><h2>espnet.nets.pytorch_backend.frontends<a class="headerlink" href="#espnet-nets-pytorch-backend-frontends" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.frontends"></span></div>
<div class="section" id="espnet-nets-pytorch-backend-nets-utils">
<span id="id25"></span><h2>espnet.nets.pytorch_backend.nets_utils<a class="headerlink" href="#espnet-nets-pytorch-backend-nets-utils" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.nets_utils"></span><dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.append_ids">
<code class="descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="descname">append_ids</code><span class="sig-paren">(</span><em>yseq</em>, <em>ids</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.append_ids" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.expand_yseq">
<code class="descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="descname">expand_yseq</code><span class="sig-paren">(</span><em>yseqs</em>, <em>next_ids</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.expand_yseq" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.get_last_yseq">
<code class="descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="descname">get_last_yseq</code><span class="sig-paren">(</span><em>exp_yseq</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.get_last_yseq" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.index_select_list">
<code class="descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="descname">index_select_list</code><span class="sig-paren">(</span><em>yseq</em>, <em>lst</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.index_select_list" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.index_select_lm_state">
<code class="descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="descname">index_select_lm_state</code><span class="sig-paren">(</span><em>rnnlm_state</em>, <em>dim</em>, <em>vidx</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.index_select_lm_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.make_pad_mask">
<code class="descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="descname">make_pad_mask</code><span class="sig-paren">(</span><em>lengths</em>, <em>xs=None</em>, <em>length_dim=-1</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.make_pad_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to make mask tensor containing indices of padded part</p>
<dl class="docutils">
<dt>e.g.: lengths = [5, 3, 2]</dt>
<dd><dl class="first last docutils">
<dt>mask = [[0, 0, 0, 0 ,0],</dt>
<dd>[0, 0, 0, 1, 1],
[0, 0, 1, 1, 1]]</dd>
</dl>
</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>lengths</strong> (<em>list</em>) – list of lengths (B)</li>
<li><strong>xs</strong> (<em>torch.Tensor</em>) – Make the shape to be like.</li>
<li><strong>length_dim</strong> (<em>int</em>) – </li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">mask tensor containing indices of padded part (B, Tmax)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.mask_by_length">
<code class="descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="descname">mask_by_length</code><span class="sig-paren">(</span><em>xs</em>, <em>length</em>, <em>fill=0</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.mask_by_length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.pad_list">
<code class="descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="descname">pad_list</code><span class="sig-paren">(</span><em>xs</em>, <em>pad_value</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.pad_list" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to pad values</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>xs</strong> (<em>list</em>) – list of torch.Tensor [(L_1, D), (L_2, D), …, (L_B, D)]</li>
<li><strong>pad_value</strong> (<em>float</em>) – value for padding</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">padded tensor (B, Lmax, D)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.th_accuracy">
<code class="descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="descname">th_accuracy</code><span class="sig-paren">(</span><em>pad_outputs</em>, <em>pad_targets</em>, <em>ignore_label</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.th_accuracy" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to calculate accuracy</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>pad_outputs</strong> (<em>torch.Tensor</em>) – prediction tensors (B*Lmax, D)</li>
<li><strong>pad_targets</strong> (<em>torch.Tensor</em>) – target tensors (B, Lmax, D)</li>
<li><strong>ignore_label</strong> (<em>int</em>) – ignore label id</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Retrun:</th><td class="field-body"><p class="first">accuracy value (0.0 - 1.0)</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">float</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.to_device">
<code class="descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="descname">to_device</code><span class="sig-paren">(</span><em>m</em>, <em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.to_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to send tensor into corresponding device</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>m</strong> (<em>torch.nn.Module</em>) – torch module</li>
<li><strong>x</strong> (<em>torch.Tensor</em>) – torch tensor</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">torch tensor located in the same place as torch module</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.Tensor</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="espnet.nets.pytorch_backend.nets_utils.to_torch_tensor">
<code class="descclassname">espnet.nets.pytorch_backend.nets_utils.</code><code class="descname">to_torch_tensor</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.pytorch_backend.nets_utils.to_torch_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Change to torch.Tensor or ComplexTensor from numpy.ndarray</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Param:</th><td class="field-body">Union[np.ndarray, torch.Tensor, ComplexTensor, dict] x:</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">Union[torch.Tensor, ComplexTensor]:<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">to_torch_tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="go">tensor([1., 1., 1.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">assert</span> <span class="n">to_torch_tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span> <span class="ow">is</span> <span class="n">xs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">xs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;real&#39;</span><span class="p">:</span> <span class="n">xs</span><span class="p">,</span> <span class="s1">&#39;imag&#39;</span><span class="p">:</span> <span class="n">xs</span><span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">to_torch_tensor</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="go">ComplexTensor(</span>
<span class="go">Real:</span>
<span class="go">tensor([1., 1., 1.])</span>
<span class="go">Imag;</span>
<span class="go">tensor([1., 1., 1.])</span>
<span class="go">)</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="espnet-nets-pytorch-backend-rnn">
<span id="id26"></span><h2>espnet.nets.pytorch_backend.rnn<a class="headerlink" href="#espnet-nets-pytorch-backend-rnn" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.rnn"></span></div>
<div class="section" id="espnet-nets-pytorch-backend-streaming">
<span id="id27"></span><h2>espnet.nets.pytorch_backend.streaming<a class="headerlink" href="#espnet-nets-pytorch-backend-streaming" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.streaming"></span></div>
<div class="section" id="espnet-nets-pytorch-backend-tacotron2">
<span id="id28"></span><h2>espnet.nets.pytorch_backend.tacotron2<a class="headerlink" href="#espnet-nets-pytorch-backend-tacotron2" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.tacotron2"></span></div>
<div class="section" id="espnet-nets-pytorch-backend-transformer">
<span id="id29"></span><h2>espnet.nets.pytorch_backend.transformer<a class="headerlink" href="#espnet-nets-pytorch-backend-transformer" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.pytorch_backend.transformer"></span></div>
<div class="section" id="espnet-nets-tts-interface">
<span id="id30"></span><h2>espnet.nets.tts_interface<a class="headerlink" href="#espnet-nets-tts-interface" title="Permalink to this headline">¶</a></h2>
<span class="target" id="module-espnet.nets.tts_interface"></span><dl class="class">
<dt id="espnet.nets.tts_interface.Reporter">
<em class="property">class </em><code class="descclassname">espnet.nets.tts_interface.</code><code class="descname">Reporter</code><span class="sig-paren">(</span><em>**links</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.tts_interface.Reporter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">chainer.link.Chain</span></code></p>
<dl class="method">
<dt id="espnet.nets.tts_interface.Reporter.report">
<code class="descname">report</code><span class="sig-paren">(</span><em>dicts</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.tts_interface.Reporter.report" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="espnet.nets.tts_interface.TTSInterface">
<em class="property">class </em><code class="descclassname">espnet.nets.tts_interface.</code><code class="descname">TTSInterface</code><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>TTS Interface for ESPnet model implementation</p>
<dl class="staticmethod">
<dt id="espnet.nets.tts_interface.TTSInterface.add_arguments">
<em class="property">static </em><code class="descname">add_arguments</code><span class="sig-paren">(</span><em>parser</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.add_arguments" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet.nets.tts_interface.TTSInterface.attention_plot_class">
<code class="descname">attention_plot_class</code><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.attention_plot_class" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="espnet.nets.tts_interface.TTSInterface.base_plot_keys">
<code class="descname">base_plot_keys</code><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.base_plot_keys" title="Permalink to this definition">¶</a></dt>
<dd><p>base key names to plot during training. keys should match what <cite>chainer.reporter</cite> reports</p>
<p>if you add the key <cite>loss</cite>, the reporter will report <cite>main/loss</cite> and <cite>validation/main/loss</cite> values.
also <cite>loss.png</cite> will be created as a figure visulizing <cite>main/loss</cite> and <cite>validation/main/loss</cite> values.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name" colspan="2">Rtype list[str] plot_keys:</th></tr>
<tr class="field-odd field"><td>&#160;</td><td class="field-body">base keys to plot during training</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.tts_interface.TTSInterface.calculate_all_attentions">
<code class="descname">calculate_all_attentions</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.calculate_all_attentions" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate TTS attention weights</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">attention weights (B, Lmax, Tmax)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">numpy array</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.tts_interface.TTSInterface.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate TTS forward propagation</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">loss value</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">torch.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="espnet.nets.tts_interface.TTSInterface.inference">
<code class="descname">inference</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#espnet.nets.tts_interface.TTSInterface.inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates the sequence of features given the sequences of characters</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">the sequence of features (L, odim)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">torch.Tensor</td>
</tr>
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">the sequence of stop probabilities (L)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">torch.Tensor</td>
</tr>
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">the sequence of attention weight (L, T)</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">torch.Tensor</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="espnet-transform.html" class="btn btn-neutral float-right" title="espnet.transform package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="espnet-lm.html" class="btn btn-neutral float-left" title="espnet.lm package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Shinji Watanabe

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>